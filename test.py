
import tensorflow as tf 
import csv
import time
import numpy as np
########################################################################################
'''
Hyper parameters for fine tuning the network

@NOTE: leave the value of NUM_EXAMPLES as 500 and num_inputs as 2
You will change the rest of them when testing the hyper paramaters in the report]

in the report, talk about changing the learning rate and seeing if it reduces
the error and cost... the values will go as like 0.1, 0.001, 0.0001, 0.00001 
'''
# Number of training or evaluation examples
NUM_EXAMPLES = 500
 # Number of inputs
NUM_INPUTS = 2
# Number of output features or class labels
NUM_LABELS = 1	
# Number of hidden/middle layer nodes
NUM_HIDDEN = 3
# tells the optimizer how far to move the weights in the direction of the gradient
LEARNING_RATE = 0.01
# Number of iterations of traversing through the data
NUM_EPOCHS = 1000

########################################################################################
'''
Basic data retrieval and sorting into lists 

@NOTE: youll need a subfolder in the main directory called data or something.. drag the
files train.csv, eval.csv into it.. trained_model.ckpt or what ever you wanna call it will
be generated by tensorflow


leave x and y [] variable names but you can change anything else here 
'''
TRAIN_DATA = 'data/train.csv'
TEST_DATA = 'data/eval.csv'
MODEL_PATH = 'data/trained_model.ckpt'

#input features and labels lists
x = []
y = []

# import training data
file  = open(TRAIN_DATA, "r")
input_data = csv.reader(file, delimiter=',')
for row in input_data:
    x.append([float(row[0]), float(row[1])])
    y.append([float(row[2])])

########################################################################################
'''
Set up the tensorflow placeholders, Create dictionaries for
the weights and biases and and network structure structure

@NOTE: you could possible change the placeholder names from x_ and y_ to 
like x_train and y_train .. but make sure you also change them in the 
feed_dict parameter in the sess.run function 

'''
x_ = tf.placeholder(tf.float32, shape=[NUM_EXAMPLES, NUM_INPUTS])
y_ = tf.placeholder(tf.float32, shape=[NUM_EXAMPLES, NUM_LABELS])


'''@NOTE: i uncommented the next part that i had and structuredn it a difference
way so it looks different, still does the same thing'''
# weights = {
#     #                       2 inputs, 2 hidden layer nodes
#     'w_1': tf.Variable(tf.random_uniform([NUM_INPUTS, NUM_HIDDEN], -1, 1)),
#     # 'w_2': tf.Variable(tf.random_uniform([NUM_HIDDEN, NUM_HIDDEN], -1, 1)),  
#     'out': tf.Variable(tf.random_uniform([NUM_HIDDEN, NUM_LABELS], -1, 1))
# }

# biases = {
#     #                       2 hidden
#     'b_1': tf.Variable(tf.zeros([NUM_HIDDEN])),
#     # 'b_2': tf.Variable(tf.random_normal([NUM_HIDDEN])),
#     'out': tf.Variable(tf.zeros([NUM_LABELS]))
# }

# layer_1 = tf.sigmoid(tf.matmul(x_, weights['w_1']) + biases['b_1'])
# # layer_2 = tf.sigmoid(tf.matmul(layer_1, weights['w_2']) + biases['b_2'])
# output_layer = tf.sigmoid(tf.matmul(layer_1, weights['out']) + biases['out'])


'''@NOTE uncomment the middle lines of each when adding a new layer'''
weight1 = tf.Variable(tf.random_uniform([NUM_INPUTS, NUM_HIDDEN], -1, 1))
# weight2: tf.Variable(tf.random_uniform([NUM_HIDDEN, NUM_HIDDEN], -1, 1)),  
weight_out =tf.Variable(tf.random_uniform([NUM_HIDDEN, NUM_LABELS], -1, 1))

bias1 = tf.Variable(tf.zeros([NUM_HIDDEN]))
# bias2: tf.Variable(tf.zeros([NUM_HIDDEN])),
bias_out =tf.Variable(tf.zeros([NUM_LABELS]))



#Add layers to the network
layer_1 = tf.sigmoid(tf.matmul(x_, weight1) + bias1)
# layer_2 = tf.sigmoid(tf.matmul(layer_1, weights['w_2']) + biases['b_2'])
outlayer = tf.sigmoid(tf.matmul(layer_1, weight_out) + bias_out)


########################################################################################
'''
Define cost and optimization function for training
the network.


@NOTE dont need to change this 
'''

# Predicted output - expected output
cost = tf.reduce_sum(tf.square(outlayer - y_))
optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cost)

########################################################################################
'''
Run a tensorflow session and print the metrics to the console


@NOTE: I commented out my version and added in a different way of running a session
.. also re structure the print out statements 
'''
# with tf.Session() as sess:
#     sess.run(tf.global_variables_initializer())
#     saver = tf.train.Saver()

#     correct = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1))
#     accuracy = tf.reduce_mean(tf.cast(correct, 'float'))

#     error = 0
#     interval = 100
#     t_start = time.clock()

#     # Feed the values into the network
#     for epoch in range(0, NUM_EPOCHS):
#         op, acc, ol, c = sess.run([optimizer, accuracy,output_layer, cost], feed_dict={x_: x, y_: y})

#         if epoch % interval == 0:
#             # op, ol, c = sess.run([optimizer,output_layer, cost], feed_dict={x_: x, y_: y})
#             for i in range(len(ol)):
#                     error = abs(ol[i] - y[i])
#             print('Epoch: ', epoch,' - Accuracy: ', acc, ' - Cost: ', c,' - Error: ', error)

#     t_end = time.clock()
#     print('\n########################### FINAL RESULT ##################################')
#     print('Cost: ', c,' - Error: ', error, ' - Elapsed time: ', t_end - t_start)
#     print('###########################################################################\n')

#     #Save the model to disk
#     # save_path = saver.save(sess, MODEL_PATH)
#     # print("Model saved in file: " , save_path)


# Initialize the global variable (placeholder, cost etc...)
init = tf.global_variables_initializer()
saver = tf.train.Saver()

# initialize and run rhe session
sess = tf.Session()
sess.run(init)


correct = tf.equal(tf.argmax(outlayer, 1), tf.argmax(y, 1))
accuracy = tf.reduce_mean(tf.cast(correct, 'float'))

error = 0.0

print_interval = 100
t_start = time.clock()
# Feed the values into the network
for epoch in range(0, NUM_EPOCHS):
    #Feed the values in the dataset to the place holder, then feed the place holder to tensorflow
    # x = 2 values and y = label
    cst, acc, out, op   = sess.run([cost, accuracy, outlayer, optimizer], 
                                        feed_dict={x_: x, y_: y})
    if epoch % print_interval == 0:
        for i in range(len(out)):
            err = abs(out[i] - y[i])
        print('Epoch Num:', epoch, ', Error value: ', err, ', Cost Value: ', cst)

t = time.clock()
print('Elapsed time is', t- t_start)
# Save the model to disk
trainged_model_path = saver.save(sess, MODEL_PATH)
print("Model saved in file: " , trainged_model_path)
